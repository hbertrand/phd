%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                         CONCLUSION                                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}
\label{chap:conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary of the contributions}

The following contributions were presented in this thesis.

\paragraph*{An incremental Cholesky decomposition to reduce the cost of Bayesian optimization.}
Most of the computational cost of Bayesian optimization is in the inversion of the Gaussian process' Gram matrix. We exploited a particularity in the structure of this matrix specific to Bayesian optimization: each successive call adds new rows and columns while leaving the rest of the matrix unchanged. We have shown that this property stays true for the underlying Cholesky decomposition, and how to compute the new decomposition faster when the previous decomposition is available.

\paragraph*{A comparison of the performance of random search and Bayesian optimization.} 
We designed an experiment on a small hyper-parameter space to observe the behaviour of random search and Bayesian optimization over many runs. Bayesian optimization found better models than random search faster in the best, average and worst cases. We showed how the Gaussian process quickly became a good predictor of model performance and how the worst models were picked last. Random search behaved in accordance to the theoretical bounds we derived. Additionally we observed the distribution of models performance to be Gaussian.

\paragraph*{A new hyper-parameter optimization method combining Hyperband and Bayesian optimization.}
We proposed a method combining the strengths of Hyperband and Bayesian optimization. Model selection is done by Bayesian optimization, and model training follows Hyperband scheme. Unfortunately due to how the selection of multiple models simultaneously was handled, the method did not perform significantly better than Hyperband alone.

\paragraph*{A method to solve a classification problem of MRI field-of-view.}
Using a dataset of MRI volumes from a multitude of protocols and machines, we developed a neural network able to classify each slice of the volumes into their anatomical regions (such as head or pelvis). We improved on this neural network by using Bayesian optimization to find a better architecture providing a non-negligible performance boost. Even though the classification was done at the slice level, we showed how it could be used for robust region localization through a decision scheme maximizing the likelihood of each region.

\paragraph*{A new transfer learning method and its application to the segmentation of the kidney in 3D ultrasound images.}
Working with a dataset of 3D ultrasound kidney images across two populations, we investigated transfer learning methods for the segmentation of the kidney from one population (healthy adults) to the other (sick children). This led us to develop a new transfer learning approach, based on adding layers to the pre-trained network to predict parameters for geometric and intensity transformation. 

\paragraph*{A statistical shape model approach using deep learning.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future Work}
